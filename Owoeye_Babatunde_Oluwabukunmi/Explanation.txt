Firstly, thank you for giving me the opportunity to part in this competition.
Since the main purpose of this competition is to implement KNN algorithm from
scratch. Therefore, I will not be using any library as everything will be 
written from scratch using pure Python script.

The principle behind the k-Nearest Neighbors algorithm is a simple but 
powerful approach for making predictions. 
The fundamental mathematical principle is developed from Eucledian distance:
In mathematics, the Euclidean distance between two points in Euclidean space 
is the length of a line segment between the two points. It can be calculated 
from the Cartesian coordinates of the points using the Pythagorean theorem, 
therefore occasionally being called the Pythagorean distance. These names come
 from the ancient Greek mathematicians Euclid and Pythagoras, although Euclid
  did not represent distances as numbers, and the connection from the 
  Pythagorean theorem to distance calculation was not made until the 18th 
  century.

The distance between two objects that are not points is usually defined to be 
the smallest distance among pairs of points from the two objects. Formulas are
 known for computing distances between different types of objects, such as the
  distance from a point to a line. In advanced mathematics, the concept of 
  distance has been generalized to abstract metric spaces, and other distances
   than Euclidean have been studied. In some applications in statistics and 
   optimization, the square of the Euclidean distance is used instead of the 
   distance itself.
   
   The distances can be in one, two or multiple dimemsions in space.
   

One dimension
The distance between any two points on the real line is the absolute value of 
the numerical difference of their coordinates. Thus if p and q are two points 
on the real line, then the distance between them is given by:
 d(p,q)=|p-q|
A more complicated formula, giving the same value, but generalizing more 
readily to higher dimensions, is:
 d(p,q)={\sqrt {(p-q)^2}
In this formula, squaring and then taking the square root leaves any positive 
number unchanged, but replaces any negative number by its absolute value.

Two dimensions
In the Euclidean plane, let point {\displaystyle p}p have Cartesian 
coordinates (p1,p2)and let point q have coordinates (q1,q2). Then the distance
 between p and q is given by:

d(p,q)={\sqrt {(q1-p1)^{2}+(q2-p2)^2
This can be seen by applying the Pythagorean theorem to a right triangle with
 horizontal and vertical sides, having the line segment from p to q as its 
 hypotenuse. The two squared formulas inside the square root give the areas of
  squares on the horizontal and vertical sides, and the outer square root 
  converts the area of the square on the hypotenuse into the length of the 
  hypotenuse.
It is also possible to compute the distance for points given by polar 
coordinates. 

Higher dimensions:
In three dimensions, for points given by their Cartesian coordinates, the 
distance is d(p,q)= sqrt {(p1-q1)^2+(p2-q2)^2+(p3-q3)^2}
In general, for points given by Cartesian coordinates in n-dimensional 
Euclidean space, the distance is d(p,q)= sqrt(p1-q1)^2+(p2-q2)^2.....+(pi-qi)^2
+......+(pn-qn)^2.

FOR THE PURPOSE OF THIS COMPRTITION:
First i develop each piece of the algorithm, then we will tie all of the 
elements together into a working implementation and then applied it to a real 
dataset.

This k-Nearest Neighbors algorithm is broken down into 3 parts:

Step 1: I Calculated the Euclidean Distance.
Step 2: I Got the Nearest Neighbors.
Step 3: I Made Predictions.
